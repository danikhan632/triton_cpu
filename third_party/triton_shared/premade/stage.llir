; ModuleID = 'LLVMDialectModule'
source_filename = "LLVMDialectModule"

declare ptr @malloc(i64)

declare void @free(ptr)

define <vscale x 4 x i32> @arm_sve_sdot(<vscale x 16 x i8> %0, <vscale x 16 x i8> %1, <vscale x 4 x i32> %2) {
  %4 = call <vscale x 4 x i32> @llvm.aarch64.sve.sdot.nxv4i32(<vscale x 4 x i32> %2, <vscale x 16 x i8> %0, <vscale x 16 x i8> %1)
  ret <vscale x 4 x i32> %4
}

define <vscale x 4 x i32> @arm_sve_smmla(<vscale x 16 x i8> %0, <vscale x 16 x i8> %1, <vscale x 4 x i32> %2) {
  %4 = call <vscale x 4 x i32> @llvm.aarch64.sve.smmla.nxv4i32(<vscale x 4 x i32> %2, <vscale x 16 x i8> %0, <vscale x 16 x i8> %1)
  ret <vscale x 4 x i32> %4
}

define <vscale x 4 x i32> @arm_sve_udot(<vscale x 16 x i8> %0, <vscale x 16 x i8> %1, <vscale x 4 x i32> %2) {
  %4 = call <vscale x 4 x i32> @llvm.aarch64.sve.udot.nxv4i32(<vscale x 4 x i32> %2, <vscale x 16 x i8> %0, <vscale x 16 x i8> %1)
  ret <vscale x 4 x i32> %4
}

define <vscale x 4 x i32> @arm_sve_ummla(<vscale x 16 x i8> %0, <vscale x 16 x i8> %1, <vscale x 4 x i32> %2) {
  %4 = call <vscale x 4 x i32> @llvm.aarch64.sve.ummla.nxv4i32(<vscale x 4 x i32> %2, <vscale x 16 x i8> %0, <vscale x 16 x i8> %1)
  ret <vscale x 4 x i32> %4
}

define <vscale x 4 x i32> @arm_sve_masked_arithi(<vscale x 4 x i32> %0, <vscale x 4 x i32> %1, <vscale x 4 x i32> %2, <vscale x 4 x i32> %3, <vscale x 4 x i32> %4, <vscale x 4 x i1> %5) {
  %7 = call <vscale x 4 x i32> @llvm.aarch64.sve.mul.nxv4i32(<vscale x 4 x i1> %5, <vscale x 4 x i32> %0, <vscale x 4 x i32> %1)
  %8 = call <vscale x 4 x i32> @llvm.aarch64.sve.add.nxv4i32(<vscale x 4 x i1> %5, <vscale x 4 x i32> %7, <vscale x 4 x i32> %2)
  %9 = call <vscale x 4 x i32> @llvm.aarch64.sve.sub.nxv4i32(<vscale x 4 x i1> %5, <vscale x 4 x i32> %8, <vscale x 4 x i32> %3)
  %10 = call <vscale x 4 x i32> @llvm.aarch64.sve.sdiv.nxv4i32(<vscale x 4 x i1> %5, <vscale x 4 x i32> %9, <vscale x 4 x i32> %4)
  %11 = call <vscale x 4 x i32> @llvm.aarch64.sve.udiv.nxv4i32(<vscale x 4 x i1> %5, <vscale x 4 x i32> %10, <vscale x 4 x i32> %4)
  ret <vscale x 4 x i32> %9
}

define <vscale x 4 x float> @arm_sve_masked_arithf(<vscale x 4 x float> %0, <vscale x 4 x float> %1, <vscale x 4 x float> %2, <vscale x 4 x float> %3, <vscale x 4 x float> %4, <vscale x 4 x i1> %5) {
  %7 = call <vscale x 4 x float> @llvm.aarch64.sve.fmul.nxv4f32(<vscale x 4 x i1> %5, <vscale x 4 x float> %0, <vscale x 4 x float> %1)
  %8 = call <vscale x 4 x float> @llvm.aarch64.sve.fadd.nxv4f32(<vscale x 4 x i1> %5, <vscale x 4 x float> %7, <vscale x 4 x float> %2)
  %9 = call <vscale x 4 x float> @llvm.aarch64.sve.fsub.nxv4f32(<vscale x 4 x i1> %5, <vscale x 4 x float> %8, <vscale x 4 x float> %3)
  %10 = call <vscale x 4 x float> @llvm.aarch64.sve.fdiv.nxv4f32(<vscale x 4 x i1> %5, <vscale x 4 x float> %9, <vscale x 4 x float> %4)
  ret <vscale x 4 x float> %10
}

define void @arm_sve_convert_to_svbool(<vscale x 1 x i1> %0, <vscale x 2 x i1> %1, <vscale x 4 x i1> %2, <vscale x 8 x i1> %3, [2 x [3 x <vscale x 1 x i1>]] %4, [4 x <vscale x 2 x i1>] %5, [1 x [1 x [1 x [2 x <vscale x 4 x i1>]]]] %6, [100 x <vscale x 8 x i1>] %7) {
  ret void
}

define void @arm_sve_convert_from_svbool(<vscale x 16 x i1> %0, [2 x [3 x <vscale x 16 x i1>]] %1, [4 x <vscale x 16 x i1>] %2, [1 x [1 x [1 x [1 x <vscale x 16 x i1>]]]] %3, [32 x <vscale x 16 x i1>] %4) {
  ret void
}

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(none)
declare <vscale x 4 x i32> @llvm.aarch64.sve.sdot.nxv4i32(<vscale x 4 x i32>, <vscale x 16 x i8>, <vscale x 16 x i8>) #0

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(none)
declare <vscale x 4 x i32> @llvm.aarch64.sve.smmla.nxv4i32(<vscale x 4 x i32>, <vscale x 16 x i8>, <vscale x 16 x i8>) #0

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(none)
declare <vscale x 4 x i32> @llvm.aarch64.sve.udot.nxv4i32(<vscale x 4 x i32>, <vscale x 16 x i8>, <vscale x 16 x i8>) #0

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(none)
declare <vscale x 4 x i32> @llvm.aarch64.sve.ummla.nxv4i32(<vscale x 4 x i32>, <vscale x 16 x i8>, <vscale x 16 x i8>) #0

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(none)
declare <vscale x 4 x i32> @llvm.aarch64.sve.mul.nxv4i32(<vscale x 4 x i1>, <vscale x 4 x i32>, <vscale x 4 x i32>) #0

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(none)
declare <vscale x 4 x i32> @llvm.aarch64.sve.add.nxv4i32(<vscale x 4 x i1>, <vscale x 4 x i32>, <vscale x 4 x i32>) #0

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(none)
declare <vscale x 4 x i32> @llvm.aarch64.sve.sub.nxv4i32(<vscale x 4 x i1>, <vscale x 4 x i32>, <vscale x 4 x i32>) #0

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(none)
declare <vscale x 4 x i32> @llvm.aarch64.sve.sdiv.nxv4i32(<vscale x 4 x i1>, <vscale x 4 x i32>, <vscale x 4 x i32>) #0

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(none)
declare <vscale x 4 x i32> @llvm.aarch64.sve.udiv.nxv4i32(<vscale x 4 x i1>, <vscale x 4 x i32>, <vscale x 4 x i32>) #0

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(none)
declare <vscale x 4 x float> @llvm.aarch64.sve.fmul.nxv4f32(<vscale x 4 x i1>, <vscale x 4 x float>, <vscale x 4 x float>) #0

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(none)
declare <vscale x 4 x float> @llvm.aarch64.sve.fadd.nxv4f32(<vscale x 4 x i1>, <vscale x 4 x float>, <vscale x 4 x float>) #0

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(none)
declare <vscale x 4 x float> @llvm.aarch64.sve.fsub.nxv4f32(<vscale x 4 x i1>, <vscale x 4 x float>, <vscale x 4 x float>) #0

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(none)
declare <vscale x 4 x float> @llvm.aarch64.sve.fdiv.nxv4f32(<vscale x 4 x i1>, <vscale x 4 x float>, <vscale x 4 x float>) #0

attributes #0 = { nocallback nofree nosync nounwind willreturn memory(none) }

!llvm.module.flags = !{!0}

!0 = !{i32 2, !"Debug Info Version", i32 3}
